# Estimation de densité

Soient $X_1, \dotsc, X_n$ des variables iid, de fonction de répartition $F$. Le problème de l'estimation de densité est celui d'estimer la densité ou la fonction de répartition de $F$ à partir de réalisations des $X_i$ : c'est un exemple typique d'estimation non-paramétrique. Dans toute la suite, on se placera dans le cas où la fonction de répartition est *continue*. 

## La répartition empirique 

L'objet central est la fonction de répartition empirique, 
$$ F_n(t) = \frac{1}{n}\#\{i : X_i \leqslant t\}.$$
La loi des grands nombres montre immédiatement que, $\mathbb{P}$-presque sûrement, $F_n(t)$ converge vers $\mathbb{P}(X_i \leqslant t)=F(t)$. On peut étendre ce résultat simultanément à une quantité dénombrable de $t$ (par exemple, $\mathbb{Q}$) mais pas à tous. De plus, ce résultat ne dit pas si la *fonction* $F_n$ est proche de la fonction $F$, au sens de la norme uniforme par exemple. Le théorème suivant, parfois appelé *théorème fondamental de l'estimation*, confirme que c'est le cas au sens de la norme uniforme^[On rappelle que $|g|_\infty = \sup_{x\in\mathbb{R}}|g(x)|$.]. 

:::{#thm-glivenko}

## Théorème de Glivenko-Cantelli

$\mathbb{P}$-presque sûrement, lorsque $n \to \infty$ on a $|F_n - F|_\infty \to 0$. 

:::

Ce théorème dit essentiellement que $F_n$ est un estimateur « convergent au sens de la norme uniforme » de $F$. On pourra également utiliser ce théorème pour faire des tests : typiquement, si $|F_n - F|$ n'est pas suffisamment proche de zéro, on rejettera l'hypothèse selon laquelle les $X_i$ ont $F$ pour fonction de répartition. Le critère exact est appelé *test de Kolmogorov-Smirnov* et sera vu dans la section suivante. 

### Calculabilité et loi  {.unnumbered}

Soit $(X_{(1)}, \dotsc, X_{(n)})$ l'échantillon trié en ordre croissant. Par convention, on pose $X_{(0)} = -\infty$. Alors, la quantité $|F_n - F|_\infty$ est aisément calculable grâce à la représentation suivante : 
$$|F_n - F|_\infty = \sup_{i\in \{0, \dotsc, n-1\}}\left|\frac{i}{n} - F(X_{(i)})\right| \vee \left| \frac{i}{n} - F(X_{(i+1)})\right|. $${#eq-supf}

:::{.proof}

La fonction $F$ est croissante, et la fonction $\hat{F}_n$ est constante par morceaux sur tous les intervalles $[X_{(i)}, X_{(i+1)}[$. En effet, à chaque $X_{(i)}$, elle saute de la valeur à gauche $(i-1)/n$ a la valeur à droite $i/n$. Ainsi, le maximum de $F - \hat{F}_n$ sur l'intervalle $[X_{(i)}, X_{(i+1)}[$ est forcément atteint à une des deux bornes, et vaut donc soit $|i/n - F(X_{(i)})|$, soit $|i/n - F(X_{(i+1)})|$, selon celui qui est le plus grand. Le supremum de $|F - \hat{F}_n|$ sur $\mathbb{R}$ étant aussi le supremum des supremums sur tous ces intervalles, la représentation ci-dessus est vraie. 

:::


:::{#lem-gc}

Si $F$ est continue, $|F_n - F|_\infty$ a la même loi que 
$$ \sup_{i\in \{0, \dotsc, n-1\}}\left|\frac{i}{n} - U_{(i)}\right| \vee \left| \frac{i}{n} - U_{(i+1)}\right|$$
où les $U_{(i)}$ sont des lois uniformes sur $[0,1]$, indépendantes, et triées dans l'ordre croissant. 

:::

:::{.proof}
Lorsque $X$ est une variable aléatoire dont la fonction de répartition $F$ est continue et strictement croissante, $F(X)$ suit une loi $\mathscr{U}[0,1]$. En effet, si $t\in [0,1]$, alors $\mathbb{P}(F(X)<t)$ est égal à $\mathbb{P}(X \leqslant F^{-1}(t))$, c'est-à-dire $F(F^{-1}(t)) = t$. Lorsque $F$ est seulement continue, la même démonstration est vraie, mais il faut remplacer l'inverse $F^{-1}(t)$ par la « transformation quantile », à savoir $F^{\leftarrow}(t) = \inf\{x : F(x)\geqslant t\}$. Les $F(X_i)$ sont donc des variables iid de loi $\mathscr{U}[0,1]$, ce qui conclut la démonstration compte tenu de @eq-supf. 

:::

En particulier, la loi de $|F_n - F|_\infty$ ne dépend pas de $F$ : on dit que cette statistique est *libre*. 


### Démonstration du théorème de Glivenko-Cantelli {.unnumbered}

Notons $q_j$ le $j$-ème quantile d'ordre $N$ de $F$ (on choisira l'entier $N$ plus tard). Soit $x$ entre $q_j$ et $q_{j+1}$. Par croissance, $F_n(x)$ est entre $F_n(q_j)$ et  $F_n(q_{j+1})$, et $F(x)$ est entre $j/N$ et $(j+1)/N$. Ainsi, $F_n(x) - F(x)$ est plus grand que 
$$ F_n(q_j) - \frac{j}{N} - \frac{1}{N}$$
et plus petit que 
$$ F_n(q_{j+1})- \frac{j}{n} = F_n(q_{j+1})- \frac{j+1}{N}  + \frac{1}{N}.$$
Quoi qu'il arrive, $|F_n(x) - F(x)|$ est plus petit que le plus grand des $|F_n(q_j) - j/N|$ augmenté de $1/N$, donc $|F_n - F|$ aussi. Pour n'importe quel $t>0$, nous pouvons utiliser la borne de l'union afin de borner $\mathbb{P}(|F_n - F|_\infty > t)$ par  $$\sum_{j=0}^N\mathbb{P}\left(\frac{1}{N} + |F_n(q_j) - j/N|>t\right).$${#eq-uniongc}
Or, $nF_n(q_j)$ suit une loi $\mathrm{Bin}(n, j/N)$, donc si^[Que se passe-t-il si $t\leqslant 1/N$ ?]  $t-1/N>0$ on peut utiliser l'inégalité de Hoeffding : 
$$\mathbb{P}\left(\frac{1}{N} + |F_n(q_j) - j/N|>t\right) \leqslant 2\exp\left\lbrace - 2 n\left(t - \frac{1}{N}\right)^2 \right\rbrace.$$
En choisissant par exemple $N = \lceil 2/N\rceil$, le terme entre parenthèses est plus grand que $t/2$, et la borne devient elle-même plus petite que $2e^{-nt^2/4}$. 
Le terme @eq-uniongc est alors plus petit que $N 2e^{-nt^2/4}$, c'est-à-dire 
$$\mathbb{P}(|F_n - F|_\infty > t) \leqslant \frac{2}{t}e^{-nt^2/4}.$${#eq-predkw}
Si l'on choisit une suite $t_n$ qui tend vers 0, et telle que $\sum_n e^{-nt_n^2/4}/t_n < \infty$, alors le lemme de Borel-Cantelli permet de conclure : presque sûrement, à partir d'un certain rang, on a $|F - F_n|_\infty \leqslant t_n$, et donc $|F_n - F|_\infty \to 0$. 

## Inégalité DKW


Le théorème de Glivenko-Cantelli possède une version beaucoup plus puissante car elle est entièrement quantitative, appelée *inégalité DKW*. 

:::{#thm-DKW}

## Dvoretzky-Kiefer-Wolfowitz
Dans le même contexte, pour tout $t>0$ on a 
$$\mathbb{P}(|F_n - F|_\infty > t) \leqslant 2e^{-2nt^2}.$${#eq-dkw}

:::

Il faut comparer ce résultat avec @eq-predkw, dans lequel la borne est effectivement décroissante en $nt^2$, mais polynomialement. L'inégalité DKW donne une décroissance *exponentielle* en $nt^2$. 
